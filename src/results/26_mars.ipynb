{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MPS\n",
    "\n",
    "# Hardware hyperparameters\n",
    "chosen_device = torch.device('cuda' \n",
    "if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Data hyperparameters\n",
    "nb_train_HP = 2000\n",
    "nb_test_HP = 500\n",
    "batch_sz_HP = 150\n",
    "batch_sz_HP = min(batch_sz_HP, nb_train_HP)\n",
    "nb_classes_HP = 10\n",
    "\n",
    "# Student hyperparameters\n",
    "# MPS parameters\n",
    "bond_dim_HP = 20\n",
    "# USING CUSTOM FEATURE MAP WITH FORK?: YES\n",
    "\n",
    "# Training parameters\n",
    "nepochs_student_HP = 25 \n",
    "student_lr_HP = 1e-4\n",
    "student_reg_HP = 0\n",
    "student_loss_HP = nn.CrossEntropyLoss()\n",
    "\n",
    "Epochs:  [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25]\n",
    "Train loss:  []\n",
    "Test loss:  [0.1, 0.31743, 0.53932, 0.58134, 0.68256, 0.78223, 0.81431, 0.82391, 0.82482, 0.82728, 0.85384, 0.85237, 0.80818, 0.85301, 0.89135, 0.87056, 0.85376, 0.89757, 0.87455, 0.88028, 0.87974, 0.86696, 0.86711, 0.85899, 0.88041]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FC to 2-MPS\n",
    "\n",
    "# Hardware hyperparameters\n",
    "chosen_device = torch.device('cuda' \n",
    "if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Data hyperparameters\n",
    "nb_train_HP = 2000\n",
    "nb_test_HP = 500\n",
    "batch_sz_HP = 150\n",
    "batch_sz_HP = min(batch_sz_HP, nb_train_HP)\n",
    "nb_classes_HP = 10\n",
    "\n",
    "# Teacher hyperparameters\n",
    "nepochs_teacher_HP = 25\n",
    "teacher_loss_HP = nn.CrossEntropyLoss()\n",
    "teacher_lr_HP = 1e-2\n",
    "teacher_reg_HP = 0.01\n",
    "teacher_hidden_size_HP = 70\n",
    "# Student hyperparameters\n",
    "# MPS parameters\n",
    "bond_dim_HP = 20\n",
    "adaptive_mode_HP = False\n",
    "periodic_bc_HP = False\n",
    "#feature_map_HP = lambda x : torch.tensor([math.cos(1.57079*x), \n",
    "                        #math.cos(1.57079*x)]).to(chosen_device)\n",
    "#feature_map_HP = lambda x : torch.tensor([1, x]).to(chosen_device)\n",
    "\n",
    "# Training parameters\n",
    "nepochs_student_HP = 25 \n",
    "student_lr_HP = 1e-4\n",
    "student_reg_HP = 0.01\n",
    "student_loss_HP = nn.KLDivLoss(reduction = \"batchmean\", log_target = True)\n",
    "\n",
    "# Gaussian parameters\n",
    "gauss_epochs_HP = 15 # number of epochs with added gaussian noise\n",
    "gn_var_HP = 0.3 #added gaussian noise variance\n",
    "gn_mean_HP = 0 #added gaussian noise mean\n",
    "#nepochs_student_HP = 25 + gauss_epochs_HP\n",
    "\n",
    "Teacher results:\n",
    "Epochs:  [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25]\n",
    "Train loss:  []\n",
    "Test loss:  [0.18517, 0.26074, 0.36587, 0.42696, 0.49921, 0.4977, 0.51645, 0.52437, 0.52214, 0.51872, 0.51776, 0.51073, 0.52645, 0.53281, 0.54118, 0.53812, 0.5304, 0.53476, 0.53532, 0.53594, 0.55177, 0.53801, 0.53558, 0.54509, 0.55231]\n",
    "\n",
    "\n",
    "Student results:\n",
    "Epochs:  [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40]\n",
    "Train loss:  []\n",
    "Test loss:  [0.1, 0.1, 0.1, 0.12209, 0.12365, 0.11153, 0.16209, 0.19439, 0.21025, 0.23537, 0.25869, 0.29623, 0.29691, 0.30466, 0.32194, 0.33375, 0.35023, 0.34048, 0.35833, 0.34815, 0.37306, 0.36089, 0.33816, 0.36145, 0.35846, 0.35619, 0.35062, 0.36355, 0.35715, 0.3607, 0.36432, 0.35858, 0.36437, 0.34559, 0.37633, 0.35167, 0.35627, 0.3661, 0.36941, 0.3641]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FC to MPS\n",
    "\n",
    "# Hardware hyperparameters\n",
    "chosen_device = torch.device('cuda' \n",
    "if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Data hyperparameters\n",
    "nb_train_HP = 2000\n",
    "nb_test_HP = 500\n",
    "batch_sz_HP = 150\n",
    "batch_sz_HP = min(batch_sz_HP, nb_train_HP)\n",
    "nb_classes_HP = 10\n",
    "\n",
    "# Teacher hyperparameters\n",
    "nepochs_teacher_HP = 25\n",
    "teacher_loss_HP = nn.CrossEntropyLoss()\n",
    "teacher_lr_HP = 1e-2\n",
    "teacher_reg_HP = 0.01\n",
    "teacher_hidden_size_HP = 70\n",
    "# Student hyperparameters\n",
    "# MPS parameters\n",
    "bond_dim_HP = 20\n",
    "adaptive_mode_HP = False\n",
    "periodic_bc_HP = False\n",
    "#feature_map_HP = lambda x : torch.tensor([1, x]).to(chosen_device)\n",
    "\n",
    "# Training parameters\n",
    "nepochs_student_HP = 25 \n",
    "student_lr_HP = 1e-4\n",
    "student_reg_HP = 0.01\n",
    "student_loss_HP = nn.KLDivLoss(reduction = \"batchmean\", log_target = True)\n",
    "\n",
    "# Gaussian parameters\n",
    "gauss_epochs_HP = 15 # number of epochs with added gaussian noise\n",
    "gn_var_HP = 0.3 #added gaussian noise variance\n",
    "gn_mean_HP = 0 #added gaussian noise mean\n",
    "nepochs_student_HP = 25 + gauss_epochs_HP\n",
    "\n",
    "Teacher results:\n",
    "Epochs:  [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25]\n",
    "Train loss:  []\n",
    "Test loss:  [0.2691, 0.37946, 0.50331, 0.5701, 0.63935, 0.65618, 0.67497, 0.69054, 0.70262, 0.7032, 0.71066, 0.71863, 0.72361, 0.71689, 0.72505, 0.72243, 0.7195, 0.71043, 0.72181, 0.7244, 0.71426, 0.70965, 0.73215, 0.72486, 0.72462]\n",
    "\n",
    "\n",
    "Student results:\n",
    "Epochs:  [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40]\n",
    "Train loss:  []\n",
    "Test loss:  [0.11157, 0.18158, 0.1, 0.23676, 0.42222, 0.53467, 0.62519, 0.66028, 0.67198, 0.70027, 0.72131, 0.69313, 0.70912, 0.71833, 0.72121, 0.70498, 0.73923, 0.74166, 0.73251, 0.7236, 0.73591, 0.74237, 0.74277, 0.74242, 0.73176, 0.207, 0.20687, 0.23711, 0.18953, 0.28831, 0.45856, 0.53183, 0.60787, 0.56993, 0.66961, 0.65222, 0.66336, 0.64327, 0.63728, 0.59261]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hardware hyperparameters\n",
    "chosen_device = torch.device('cuda' \n",
    "if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Data hyperparameters\n",
    "nb_train_HP = 2000\n",
    "nb_test_HP = 500\n",
    "batch_sz_HP = 150\n",
    "batch_sz_HP = min(batch_sz_HP, nb_train_HP)\n",
    "nb_classes_HP = 10\n",
    "\n",
    "# Teacher hyperparameters\n",
    "nepochs_teacher_HP = 25\n",
    "teacher_loss_HP = nn.CrossEntropyLoss()\n",
    "teacher_lr_HP = 1e-2\n",
    "teacher_reg_HP = 0.01\n",
    "teacher_hidden_size_HP = 70\n",
    "# Student hyperparameters\n",
    "# MPS parameters\n",
    "bond_dim_HP = 20\n",
    "adaptive_mode_HP = False\n",
    "periodic_bc_HP = False\n",
    "#feature_map_HP = lambda x : torch.tensor([1, x]).to(chosen_device)\n",
    "\n",
    "# Training parameters\n",
    "nepochs_student_HP = 25 \n",
    "student_lr_HP = 1e-4\n",
    "student_reg_HP = 0.01\n",
    "student_loss_HP = nn.KLDivLoss(reduction = \"batchmean\", log_target = True)\n",
    "\n",
    "# Gaussian parameters\n",
    "gauss_epochs_HP = 5 # number of epochs with added gaussian noise\n",
    "gn_var_HP = 0.3 #added gaussian noise variance\n",
    "gn_mean_HP = 0 #added gaussian noise mean\n",
    "nepochs_student_HP = 25 + gauss_epochs_HP\n",
    "\n",
    "\n",
    "For the teacher:\n",
    "Epochs:  [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25]\n",
    "Train loss:  []\n",
    "Test loss:  [0.23686, 0.23686, 0.47708, 0.55606, 0.61843, 0.6485, 0.66156, 0.74678, 0.73876, 0.78062, 0.78377, 0.79288, 0.78729, 0.7959, 0.82278, 0.81677, 0.81323, 0.81558, 0.82626, 0.82433, 0.83316, 0.83362, 0.83122, 0.82883, 0.81012]\n",
    "\n",
    "For the student:\n",
    "Epochs:  [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]\n",
    "Train loss:  []\n",
    "Test loss:  [0.1, 0.20006, 0.18931, 0.18345, 0.14345, 0.10774, 0.1, 0.1, 0.1, 0.1, 0.35417, 0.54244, 0.70318, 0.70479, 0.76761, 0.79412, 0.75929, 0.8157, 0.81632, 0.83185, 0.81911, 0.84946, 0.85632, 0.86082, 0.86365, 0.87515, 0.15423, 0.36633, 0.59703, 0.54122]"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
