{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create and train the MPS\n",
    "# MPS parameters\n",
    "bond_dim = 20\n",
    "adaptive_mode = False\n",
    "periodic_bc = False\n",
    "\n",
    "# Training parameters\n",
    "gn_var = 0.3 #added gaussian noise variance\n",
    "gn_mean = 0 #added gaussian noise mean\n",
    "n_epochs_lmps = 18\n",
    "mps_learn_rate = 0.0001\n",
    "mps_reg = 0.0\n",
    "mps_chosen_loss = nn.CrossEntropyLoss().to(chosen_device)\n",
    "\n",
    "\n",
    "# Initialise the local_patch MPS\n",
    "# Create the fcnn class\n",
    "class LMPS_patcher(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(LMPS_patcher, self).__init__()\n",
    "        mps_student = MPS(\n",
    "            input_dim=28 ** 2,\n",
    "            output_dim=10,\n",
    "            bond_dim=bond_dim,\n",
    "            adaptive_mode=adaptive_mode,\n",
    "            periodic_bc=periodic_bc,\n",
    "        )\n",
    "\n",
    "    def forward(self, mps_student):\n",
    "        y = self.mps(x)\n",
    "        return y\n",
    "\n",
    "student = LMPS_patcher()\n",
    "\n",
    "# Instantiate the optimizer and softmax\n",
    "student_optimizer = torch.optim.Adam(mps_student.parameters(), lr = mps_learn_rate,\n",
    "                                  weight_decay = mps_reg)\n",
    "softmax = nn.Softmax(dim=1)\n",
    "\n",
    "# Training loop \n",
    "for epoch in range(n_epochs_lmps):\n",
    "    for (x_mb, _) in train_iterator:\n",
    "        # Reshape, add gaussian noise, put on the chosen device\n",
    "        x_mb = x_mb.reshape(-1, 784).to(chosen_device)\n",
    "        x_mb = (x_mb + torch.randn(size=x_mb.size())).to(chosen_device)\n",
    "\n",
    "        # Get softmax of output of teacher\n",
    "        y_mb = (softmax(fcnn_teacher(x_mb))).to(chosen_device)\n",
    "\n",
    "        # Foward propagation\n",
    "        y_hat_mb = mps_student(x_mb)\n",
    "        loss = mps_chosen_loss(y_hat_mb, y_mb)\n",
    "\n",
    "        # Backpropagation\n",
    "        loss.backward()\n",
    "        lmps_optimizer.step()\n",
    "        lmps_optimizer.zero_grad()\n",
    "\n",
    "    print(loss.item())\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# get accuracy\n",
    "for (x_mb, y_mb) in test_iterator:\n",
    "    print(\"testing teacher\")\n",
    "    print(MulticlassAccuracy(num_classes=10)(mps_student(x_mb.reshape(-1, 784)), y_mb))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "67bfac4f4aefe1c16f1836a62d55b6e6baa7aba1ac5ce70e93ee8e90eb4f073a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
